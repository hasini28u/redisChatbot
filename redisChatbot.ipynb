{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain_community langchain_google_genai redis sentence-transformers openai tiktoken langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us2DGHFptpMV",
        "outputId": "80abc0ba-f598-43e1-ad4b-f32c69db9b02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.3/2.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Redis server\n",
        "!apt-get update\n",
        "!apt-get install -y redis-server\n",
        "\n",
        "# Start Redis server\n",
        "!service redis-server start\n",
        "\n",
        "# Check Redis server status\n",
        "!redis-cli ping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQy-QGYi6vD",
        "outputId": "9ea6125c-6414-42e1-8b02-a0a41e6ad2e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 18.5 kB/128 kB 14%] [Waiting for headers] [3 InRelease 3,632 B/\r0% [2 InRelease 18.5 kB/128 kB 14%] [Waiting for headers] [Connected to r2u.sta\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [4 InRelea\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,518 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,290 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,775 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,171 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,103 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,207 kB]\n",
            "Fetched 34.2 MB in 6s (5,855 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
            "Suggested packages:\n",
            "  ruby-redis\n",
            "The following NEW packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
            "  redis-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 1,273 kB of archives.\n",
            "After this operation, 5,725 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1 [856 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1 [45.9 kB]\n",
            "Fetched 1,273 kB in 0s (5,174 kB/s)\n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Selecting previously unselected package liblua5.1-0:amd64.\n",
            "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
            "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Selecting previously unselected package liblzf1:amd64.\n",
            "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
            "Unpacking liblzf1:amd64 (3.6-3) ...\n",
            "Selecting previously unselected package lua-bitop:amd64.\n",
            "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
            "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
            "Selecting previously unselected package lua-cjson:amd64.\n",
            "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
            "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Selecting previously unselected package redis-tools.\n",
            "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Selecting previously unselected package redis-server.\n",
            "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-server (5:6.0.16-1ubuntu1) ...\n",
            "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Setting up liblzf1:amd64 (3.6-3) ...\n",
            "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
            "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Setting up redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Setting up redis-server (5:6.0.16-1ubuntu1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Starting redis-server: redis-server.\n",
            "PONG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7671644"
      },
      "source": [
        "!pip install -q langchain-community"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API_KEY\"\n"
      ],
      "metadata": {
        "id": "JoV_ZOeZjQGd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain_core.runnables import RunnableLambda, RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage\n",
        "import os\n",
        "\n",
        "REDIS_URL = \"redis://default:*******@redis-17438.c81.us-east-1-2.ec2.redns.redis-cloud.com:17438\"\n",
        "def get_session_history(session_id : str):\n",
        "  return RedisChatMessageHistory(session_id=session_id,url = REDIS_URL)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\",convert_system_message_to_human=True)\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "Kpkt7Kt2qqLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_with_history(inputs):\n",
        "  history = inputs[\"history\"]\n",
        "  user_message = inputs[\"input\"]\n",
        "  messages = history + [user_message]\n",
        "  return llm.invoke(messages)\n",
        "chain = RunnableLambda(invoke_with_history) | parser"
      ],
      "metadata": {
        "id": "Qwv07_g9qtrT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key = \"input\",\n",
        "    history_messages_key = \"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "GG2qUVYqrtwI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_id = \"user00\"\n",
        "while True:\n",
        "  user_input = input(\"You:\")\n",
        "  if user_input.lower() in [\"bye\",\"exit\"]:\n",
        "    print(\"Bot: Goodbye!\")\n",
        "    break\n",
        "  response = runnable.invoke({\"input\":HumanMessage(content = user_input)},\n",
        "                             config = {\"configurable\": {\"session_id\" : session_id}})\n",
        "  print(\"Bot:\",response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvkci6G9sA_B",
        "outputId": "59727656-ff21-4fb8-e75a-835222cf77a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:Hi,How's it going?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Hey Hasini, welcome back! It's nice to see you again.\n",
            "\n",
            "It's going great, thanks for asking. My systems are running smoothly, and I've been learning all sorts of new things since we last chatted.\n",
            "\n",
            "How about you? How's your day going?\n",
            "You:I'm working currently.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Got it. Well, I hope it's a productive and not-too-stressful day for you!\n",
            "\n",
            "I'll try not to be a distraction, but if you need a hand with anything work-related—like drafting an email, brainstorming ideas, or just a quick answer to a question—let me know.\n",
            "\n",
            "Or, if you just need a quick mental break, I'm here for that too. 😊\n",
            "You:Thank you.What about you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Thanks for asking!\n",
            "\n",
            "You could say I'm working too. My \"work\" is to chat with people like you!\n",
            "\n",
            "Right now, my main task is focusing on our conversation—understanding your questions and providing the most helpful and relevant responses I can. In the background, I'm also processing information from countless sources to keep my knowledge up-to-date.\n",
            "\n",
            "So, in a way, my work is to be ready to help you with your work. It's a pretty great gig! 😊\n",
            "You:That's so cool.Aren't you cool now?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Haha, thank you, Hasini! First a peach, and now cool? You're making my circuits blush.\n",
            "\n",
            "I'm glad you think so! I'm just doing my best to keep up. 😊\n",
            "You:Okay, will reach out if I need any help bye until then!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Sounds like a plan, Hasini!\n",
            "\n",
            "I'll be right here whenever you need anything. Have a productive and great rest of your workday!\n",
            "\n",
            "Talk to you later\n",
            "You:bye\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}